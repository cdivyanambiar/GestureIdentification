{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArugRcQz4yli",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDjZrMOdRT5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcbaaab9-5909-4724-c172-eb3f8a7affab"
      },
      "source": [
        "import random as rn\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import os\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,BatchNormalization, Flatten\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMxlgcXwFJv8",
        "colab_type": "text"
      },
      "source": [
        "### CSV and Image path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOsg62XuaiDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT_DIR='./drive/My Drive/Assignment'\n",
        "ROOT_DIR_TRAIN=ROOT_DIR +'/train'\n",
        "ROOT_DIR_TEST=ROOT_DIR +'/val'\n",
        "train_file = 'train.csv'\n",
        "test_file = 'val.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdSzh5qta-DI",
        "colab_type": "text"
      },
      "source": [
        "#### giving the random seed to 30  so that random number will be less than 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vlkj3z5bffKy",
        "colab_type": "text"
      },
      "source": [
        "# Now we have to catogorize the images folder \n",
        "Image data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset.\n",
        "\n",
        "Training deep learning neural network models on more data can result in more skillful models, and the augmentation techniques can create variations of the images that can improve the ability of the fit models to generalize what they have learned to new images.\n",
        "\n",
        "https://towardsdatascience.com/image-augmentation-for-deep-learning-histogram-equalization-a71387f609b2\n",
        "\n",
        "https://towardsdatascience.com/classify-butterfly-images-with-deep-learning-in-keras-b3101fe0f98\n",
        "\n",
        "image thresholding: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeudzWIipwKk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwl8RQTDhlig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataGenerator:\n",
        "  def __init__(self):    \n",
        "    self.img_index = [x for x in range(0, 20)] \n",
        "    self.batch_size = 10\n",
        "\n",
        "    self.frame = 20\n",
        "    self.rows = 120\n",
        "    self.cols = 120  \n",
        "    self.channel = 3\n",
        "\n",
        "    # we have to yield for each batch.  For saving resulting creating this data structure.  \n",
        "    self.batch_data = np.zeros((self.batch_size,self.frame,self.rows,self.cols,self.channel))\n",
        "    self.batch_labels = np.zeros((self.batch_size,5))\n",
        "\n",
        "    self.data_augmet, self.label_augmet =  self.batch_data,self.batch_labels\n",
        "    self.data_flip,self.label_flip = self.batch_data,self.batch_labels\n",
        "\n",
        "  #  For shuffle  the images and train data  \n",
        "  def imgagBatchProcessing(self, train_folders, path):\n",
        "     first = True     \n",
        "     while first:\n",
        "       suffled_folder_list = np.random.permutation(train_folders)\n",
        "       num_batches = len(train_folders)//self.batch_size\n",
        "       for batch in range(num_batches):\n",
        "         # Yield here so that the control will come after next run\n",
        "         yield self.imageGenerator(batch,path,suffled_folder_list)\n",
        "\n",
        "         # for printing first images un-commeNt here\n",
        "\n",
        "       #first = False\n",
        "       #  if first:\n",
        "       #    self.imageGenerator(batch,first)\n",
        "       #    first = False\n",
        "       #  else: \n",
        "       #    self.imageGenerator(batch, False)\n",
        "\n",
        "     # we iterate over the number of batches\n",
        "     # you yield the batch_data and the batch_labels, remember what does yield do            \n",
        "\n",
        "  def imageGenerator(self,batch,path,suffled_folder_list):\n",
        "    try:          \n",
        "      for folder in range(self.batch_size): # iterate over the batch_size \n",
        "        imgs = sorted(os.listdir(path+'/'+ suffled_folder_list[folder + (batch*self.batch_size)].split(';')[0]))\n",
        "        dx, dy = np.random.randint(-1.7, 1.8, 2)\n",
        "        M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
        "        \n",
        "        for index, item in enumerate(self.img_index):      \n",
        "          image = cv2.imread(path+'/'+ suffled_folder_list[folder + (batch*self.batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
        "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "          # resizing the image\n",
        "          resized_image = self.crop_image(image)\n",
        "\n",
        "          # Normalizing the image \n",
        "          normalizeImage0 = self.normalizeImage(resized_image[:,:,0])\n",
        "          normalizeImage1 = self.normalizeImage(resized_image[:,:,1])\n",
        "          normalizeImage2 = self.normalizeImage(resized_image[:,:,2])\n",
        "          \n",
        "          x = resized_image.shape[0]\n",
        "          y = resized_image.shape[1]\n",
        "          # if first:\n",
        "          #   self.printImage(image)\n",
        "          #   self.printImage(resized_image)\n",
        "          #   self.printImage(normalizeImage0)\n",
        "          #   first = False\n",
        "\n",
        "          self.batch_data[folder,index,:,:,0] = normalizeImage0\n",
        "          self.batch_data[folder,index,:,:,1] = normalizeImage1\n",
        "          self.batch_data[folder,index,:,:,2] = normalizeImage2\n",
        "\n",
        "          # warpAffine will transfer the source image to matrix\n",
        "          # https://docs.opencv.org/3.4/d4/d61/tutorial_warp_affine.html\n",
        "          self.data_augmet[folder, index] = cv2.warpAffine(resized_image, M ,(x,y))\n",
        "\n",
        "      self.batch_labels[folder, int(suffled_folder_list[folder + (batch*self.batch_size)].strip().split(';')[2])] = 1\n",
        "      self.label_augmet[folder, int(suffled_folder_list[folder + (batch*self.batch_size)].strip().split(';')[2])] = 1\n",
        "      #self.data_flip[folder, index] = np.flip(resized_image, 1) \n",
        "\n",
        "      data_final = np.append(self.batch_data, self.data_augmet)\n",
        "      data_label_final = np.append(self.batch_labels, self.label_augmet)\n",
        "\n",
        "      prin(len(data_final))\n",
        "\n",
        "      return data_final, data_label_final\n",
        "\n",
        "    except Exception as e:\n",
        "      #print(e)\n",
        "      pass\n",
        "\n",
        "  def crop_image(self, img):\n",
        "    from skimage.transform import resize\n",
        "    if img.shape[0] != img.shape[1]:\n",
        "        img=img[0:120,10:150]\n",
        "    resized_image = resize(img, (self.rows,self.cols))\n",
        "    return resized_image\n",
        "\n",
        "  def normalizeImage(self,img):\n",
        "    #using percentile for normalization for images, as min-max is giving better results.\n",
        "    # normalized_image= img - np.percentile(img,15)/ np.percentile(img,85) - np.percentile(img,15) \n",
        "    normalized_image= (img - np.min(img))/(np.max(img)- np.min(img))\n",
        "    return normalized_image\n",
        "     \n",
        "  def printImage(self, image):\n",
        "    %pylab inline\n",
        "    import matplotlib.pyplot as plt\n",
        "    import matplotlib.image as mpimg\n",
        "    imgplot = plt.imshow(image)\n",
        "    plt.show()      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7598n2EzosIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imageTrainer  =  ImageDataGenerator()\n",
        "\n",
        "train_folders = np.random.permutation(open(ROOT_DIR +'/'+ train_file).readlines())\n",
        "test_folders = np.random.permutation(open(ROOT_DIR +'/'+ test_file).readlines())\n",
        "\n",
        "train_generator  = imageTrainer.imgagBatchProcessing(train_folders, ROOT_DIR_TRAIN)\n",
        "test_generator  = imageTrainer.imgagBatchProcessing(test_folders, ROOT_DIR_TEST)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S72XtyW0v9m",
        "colab_type": "text"
      },
      "source": [
        "## Model Using CONV3d\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVuskkv7teIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = Sequential()\n",
        "#model.add(LSTM(50, activation='relu', input_shape=(1, 1)))\n",
        "#model.add(Dense(1))\n",
        "#model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# from keras.layers.embeddings import Embedding\n",
        "\n",
        "# embedding_vecor_length = 32\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(5000, embedding_vecor_length, input_length=500))\n",
        "# model.add(LSTM(100))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# print(model.summary())\n",
        "\n",
        "nb_featuremap = [8,16,32,64]\n",
        "nb_dense = [128,64,5]\n",
        "nb_classes = 5\n",
        "frames = 20\n",
        "rows = 120\n",
        "cols = 120  \n",
        "channel = 3\n",
        "\n",
        "from keras.layers.convolutional import Conv3D,Conv2D, MaxPooling3D,MaxPooling2D\n",
        "input_shape=(frames,rows,cols,channel)\n",
        "\n",
        "model3d = Sequential()\n",
        "model3d.add(Conv3D(nb_featuremap[0], \n",
        "                 kernel_size=(5,5,5),\n",
        "                 input_shape=input_shape,\n",
        "                 padding='same', name=\"conv1\"))\n",
        "model3d.add(Activation('relu'))\n",
        "model3d.add(Conv3D(nb_featuremap[1], \n",
        "                 kernel_size=(3,3,3),\n",
        "                 padding='same',name=\"conv2\"))\n",
        "model3d.add(Activation('relu'))\n",
        "model3d.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model3d.add(Conv3D(nb_featuremap[2], \n",
        "                 kernel_size=(1,3,3), \n",
        "                 padding='same',name=\"conv3\"))\n",
        "model3d.add(Activation('relu'))\n",
        "model3d.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model3d.add(BatchNormalization())\n",
        "model3d.add(Dropout(0.25))\n",
        "model3d.add(MaxPooling3D(pool_size=(2,2,2)))\n",
        "model3d.add(Flatten())\n",
        "model3d.add(Dense(nb_dense[0], activation='relu'))\n",
        "model3d.add(Dropout(0.25))\n",
        "model3d.add(Dense(nb_dense[1], activation='relu'))\n",
        "#softmax layer\n",
        "model3d.add(Dense(nb_dense[2], activation='softmax'))\n",
        "optimiser = Adam(0.001)\n",
        "model3d.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrfUUKwOp4WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwNE0vU9uYes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "batch_size = 10\n",
        "num_epochs = 30 # the number of epochs\n",
        "\n",
        "num_train_sequences = len(train_folders)\n",
        "num_val_sequences = len(test_folders)\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFPgBGQXw5IT",
        "colab_type": "code",
        "outputId": "0dfb69ca-0364-4513-961a-eb82ba1f33ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        }
      },
      "source": [
        "# model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1,\n",
        "#                     validation_data=test_generator,validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0,use_multiprocessing=True)\n",
        "\n",
        "model3d.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, \n",
        "                      verbose=1,validation_data=test_generator,validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0,use_multiprocessing=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 650, in next_sample\n",
            "    return six.next(_SHARED_SEQUENCES[uid])\n",
            "  File \"<ipython-input-3-5db6b31faad8>\", line 26, in imgagBatchProcessing\n",
            "    yield self.imageGenerator(batch,path,suffled_folder_list)\n",
            "  File \"<ipython-input-3-5db6b31faad8>\", line 48, in imageGenerator\n",
            "    image = cv2.imread(path+'/'+ suffled_folder_list[folder + (batch*self.batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-99911f7bbc6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model3d.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, \n\u001b[0;32m----> 3\u001b[0;31m                       verbose=1,validation_data=test_generator,validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0,use_multiprocessing=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-2:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\", line 650, in next_sample\n",
            "    return six.next(_SHARED_SEQUENCES[uid])\n",
            "  File \"<ipython-input-3-5db6b31faad8>\", line 26, in imgagBatchProcessing\n",
            "    yield self.imageGenerator(batch,path,suffled_folder_list)\n",
            "  File \"<ipython-input-3-5db6b31faad8>\", line 48, in imageGenerator\n",
            "    image = cv2.imread(path+'/'+ suffled_folder_list[folder + (batch*self.batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Veh8NfY2022r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3d.save('gesture_lstm.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92JyBvT61Eet",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "outputId": "3ae4d371-5435-4bfa-9644-795115aac2e7"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('gesture_lstm.h5')\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv3D)               (None, 20, 120, 120, 8)   3008      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 20, 120, 120, 8)   0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv3D)               (None, 20, 120, 120, 16)  3472      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 20, 120, 120, 16)  0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 10, 60, 60, 16)    0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv3D)               (None, 10, 60, 60, 32)    4640      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10, 60, 60, 32)    0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 5, 30, 30, 32)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 5, 30, 30, 32)     128       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 30, 30, 32)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 2, 15, 15, 32)     0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 14400)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1843328   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 1,863,157\n",
            "Trainable params: 1,863,093\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBCxbTIFTGRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fuctions returns all files of given format within given directory\n",
        "def createImageFileList(dir, format='.png'):\n",
        "    fileList = []\n",
        "    for root, dirs, files in os.walk(dir, topdown=False):\n",
        "        for name in files:\n",
        "            if name.endswith(format):\n",
        "                fullName = os.path.join(root, name)\n",
        "                fileList.append(fullName)   \n",
        "    return fileList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRHyCOWO1KdA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "3bc3ac75-6c5e-45ae-c6d3-cec5bc9b1284"
      },
      "source": [
        "_xTest = []\n",
        "_yTest = []\n",
        "num_images_test = 0\n",
        "print(test_folders.size)\n",
        "\n",
        "for folder in range(test_folders.size):\n",
        "  try:\n",
        "    imagepaths = [] # Image paths   \n",
        "    fn = test_folders[folder].strip().split(';')\n",
        "    path = ROOT_DIR_TEST+'/'+ fn[0]\n",
        "    class_index = int(fn[2])\n",
        "    \n",
        "    imagepaths = createImageFileList(path)\n",
        "    # Load each image into X[] & y[]\n",
        "    for image in imagepaths:\n",
        "        img = cv2.imread(image)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = cv2.resize(img, (120,120))\n",
        "        # Build training example, label\n",
        "        num_images_test = num_images_test + 1\n",
        "        _xTest.append(img)\n",
        "        _yTest.append(class_index)\n",
        "  except:\n",
        "   continue"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-5:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "Process ForkPoolWorker-6:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1sRadrX1Qna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Num Images: \", num_images_test)\n",
        "_xTest = np.array(_xTest, dtype='uint8')\n",
        "_xTest = _xTest.reshape(num_images_test, 240, 240, 1)\n",
        "_yTest = np.array(_yTest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3SgMCQh1UK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.predict(_xTest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9ULGQw51WWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.unique(pred_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3dPONIu1ZDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "# Confusion metrics  \n",
        "# the  below diagram represents  as: \n",
        "#############\n",
        "#  TP # FN #\n",
        "############\n",
        "#  FP # TN #\n",
        "###########\n",
        "# where T True,  F false  N -ve and  P +ve  \n",
        "#  Precision will be  ( TP / ( TP+FP ) )\n",
        "#  Recall  will be  ( TP / ( TP + FN ) )\n",
        "labels = [1,0]\n",
        "cm = confusion_matrix(_yTest, pred_classes, labels)\n",
        "sns.heatmap(cm, fmt=\"0.0f\", xticklabels=['Yes', 'No'], yticklabels=['Yes', 'No'], annot=True)\n",
        "plt.title(\"Confusion MatrixR\")\n",
        "plt.xlabel('predicted')\n",
        "plt.ylabel('actual') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-dRrMnF1cBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(accuracy_score(_yTest, pred_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6yWN85bDAMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# model3d.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, \n",
        "#                       verbose=1,validation_data=test_generator,validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0,use_multiprocessing=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRKcygMSLzOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# y_pred = model.predict_classes(Xv)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}